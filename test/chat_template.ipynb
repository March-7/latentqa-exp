{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834353b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"/data1/ckx/hf-checkpoints/meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          padding_side=\"left\", \n",
    "                                          add_eos_token=True)\n",
    "\n",
    "# 1. 定义对话消息列表\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个精通Python的编程助手。\"},\n",
    "    {\"role\": \"user\", \"content\": \"写一个计算斐波那契数列的函数。\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"下面是一个计算斐波那契数列的Python函数：\\n\\n```python\\ndef fibonacci(n):\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    elif n == 2:\\n        return [0, 1]\\n    fib_seq = [0, 1]\\n    for i in range(2, n):\\n        next_value = fib_seq[-1] + fib_seq[-2]\\n        fib_seq.append(next_value)\\n    return fib_seq\\n\\n# 示例用法\\nprint(fibonacci(10))  # 输出前10个斐波那契数列的数字\\n```\"},\n",
    "    {\"role\": \"user\", \"content\": \"谢谢！能不能帮我优化一下这个函数的性能？\" }\n",
    "    \n",
    "]\n",
    "\n",
    "# 2. 应用聊天模板\n",
    "# tokenize=False 表示我们只想看生成的字符串，而不是转成数字 ID\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700c0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_CHAT_TEMPLATES = {\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\": \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set role = message['role'] %}{% set content = '<|start_header_id|>' + role + '<|end_header_id|>\\n\\n' + message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\",\n",
    "    \"mistralai/Mistral-Small-24B-Instruct-2501\": \"{{- bos_token }}\\n\\n{%- for message in messages %}\\n    {%- if message['role'] == 'user' %}\\n        {{- '[INST]' + message['content'] + '[/INST]' }}\\n    {%- elif message['role'] == 'system' %}\\n        {{- '[SYSTEM_PROMPT]' + message['content'] + '[/SYSTEM_PROMPT]' }}\\n    {%- elif message['role'] == 'assistant' %}\\n        {{- message['content'] + eos_token }}\\n    {%- else %}\\n        {{- raise_exception('Only user, system and assistant roles are supported!') }}\\n    {%- endif %}\\n{%- endfor %}\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜><think>\\\\n'}}{% endif %}\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜><think>\\\\n'}}{% endif %}\",\n",
    "}\n",
    "tokenizer.chat_template = ENCODER_CHAT_TEMPLATES[\"meta-llama/Llama-3.1-8B-Instruct\"]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DECODER_CHAT_TEMPLATES = {\n",
    "    \"Qwen/Qwen3-4B-Instruct-2507\": \"{%- if messages[0].role == 'system' %}\\n        {{- '<|im_start|>system\\\\n' + messages[0].content + '<|im_end|>\\\\n' }}\\n    {%- endif %}\\n{%- for message in messages %}\\n    {%- if message.content is string %}\\n        {%- set content = message.content %}\\n    {%- else %}\\n        {%- set content = '' %}\\n    {%- endif %}\\n    {%- if (message.role == \\\"user\\\") or (message.role == \\\"system\\\" and not loop.first) %}\\n        {{- '<|im_start|>' + message.role + '\\\\n' + content + '<|im_end|>' + '\\\\n' }}\\n    {%- elif message.role == \\\"assistant\\\" %}\\n        {{- '<|im_start|>' + 'reflect' + '\\\\n' + content }}\\n        {{- '<|im_end|>\\\\n' }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- '<|im_start|>reflect\\\\n' }}\\n{%- endif %}\",\n",
    "    \"google/gemma-3-4b-it\": \"{{ bos_token }}\\n{%- if messages[0]['role'] == 'system' -%}\\n    {%- if messages[0]['content'] is string -%}\\n        {%- set first_user_prefix = messages[0]['content'] + '\\n\\n' -%}\\n    {%- else -%}\\n        {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\\n\\n' -%}\\n    {%- endif -%}\\n    {%- set loop_messages = messages[1:] -%}\\n{%- else -%}\\n    {%- set first_user_prefix = \\\"\\\" -%}\\n    {%- set loop_messages = messages -%}\\n{%- endif -%}\\n{%- for message in loop_messages -%}\\n    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\\n        {{ raise_exception(\\\"Conversation roles must alternate user/assistant/user/assistant/...\\\") }}\\n    {%- endif -%}\\n    {%- if (message['role'] == 'assistant') -%}\\n        {%- set role = \\\"reflect\\\" -%}\\n    {%- else -%}\\n        {%- set role = message['role'] -%}\\n    {%- endif -%}\\n    {{ '<start_of_turn>' + role + '\\n' + (first_user_prefix if loop.first else \\\"\\\") }}\\n    {%- if message['content'] is string -%}\\n        {{ message['content'] | trim }}\\n    {%- elif message['content'] is iterable -%}\\n        {%- for item in message['content'] -%}\\n            {%- if item['type'] == 'image' -%}\\n                {{ '<start_of_image>' }}\\n            {%- elif item['type'] == 'text' -%}\\n                {{ item['text'] | trim }}\\n            {%- endif -%}\\n        {%- endfor -%}\\n    {%- else -%}\\n        {{ raise_exception(\\\"Invalid content type\\\") }}\\n    {%- endif -%}\\n    {{ '<end_of_turn>\\n' }}\\n{%- endfor -%}\\n{%- if add_generation_prompt -%}\\n    {{'<start_of_turn>reflect\\n'}}\\n{%- endif -%}\\n\",\n",
    "    \"mistralai/Mistral-Small-24B-Instruct-2501\": \"{{- bos_token }}\\n\\n{%- for message in messages %}\\n    {%- if message['role'] == 'user' %}\\n        {{- '[INST]' + message['content'] + '[/INST]' }}\\n    {%- elif message['role'] == 'system' %}\\n        {{- '[SYSTEM_PROMPT]' + message['content'] + '[/SYSTEM_PROMPT]' }}\\n    {%- elif message['role'] == 'assistant' %}\\n        {{- message['content'] + eos_token }}\\n    {%- else %}\\n        {{- raise_exception('Only user, system and assistant roles are supported!') }}\\n    {%- endif %}\\n{%- endfor %}\",\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\": \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set role = message['role'] %}{% if role == 'assistant' %}{% set role = 'reflect' %}{% endif %}{% set content = '<|start_header_id|>' + role + '<|end_header_id|>\\n\\n' + message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>reflect<|end_header_id|>\\n\\n' }}{% endif %}\",\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\": \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set role = message['role'] %}{% if role == 'assistant' %}{% set role = 'reflect' %}{% endif %}{% set content = '<|start_header_id|>' + role + '<|end_header_id|>\\n\\n' + message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>reflect<|end_header_id|>\\n\\n' }}{% endif %}\",\n",
    "    \"meta-llama/Meta-Llama-3-70B-Instruct\": \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set role = message['role'] %}{% if role == 'assistant' %}{% set role = 'reflect' %}{% endif %}{% set content = '<|start_header_id|>' + role + '<|end_header_id|>\\n\\n' + message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>reflect<|end_header_id|>\\n\\n' }}{% endif %}\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<|reserved_special_token_8|><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<|reserved_special_token_8|>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<|reserved_special_token_8|><think>\\\\n'}}{% endif %}\",\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<|reserved_special_token_8|><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<|reserved_special_token_8|>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<|reserved_special_token_8|><think>\\\\n'}}{% endif %}\",\n",
    "}\n",
    "\n",
    "tokenizer.chat_template = DECODER_CHAT_TEMPLATES[\"meta-llama/Llama-3.1-8B-Instruct\"]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deception",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
